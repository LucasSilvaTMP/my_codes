{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ce05739-145e-4172-af40-15eedb98b19f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olx_datalake configurado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FINISHED: 100%|██████████| 7383/7383 [02:37<00:00, 46.76 splits/s] \n",
      "FINISHED: 100%|██████████| 6225/6225 [00:34<00:00, 181.55 splits/s]\n",
      "FINISHED: 100%|██████████| 2047/2047 [01:32<00:00, 22.12 splits/s]\n",
      "FINISHED: 100%|██████████| 1574/1574 [01:35<00:00, 16.55 splits/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  publi_month  quintoandar      loft  imovelweb  casamineira           zap  \\\n",
      "0  2023-06-01     215941.4  91472.40  3712163.4    1965700.6  6.891894e+06   \n",
      "1  2023-07-01     223527.0  93198.25  3419960.2    1833958.5  6.993771e+06   \n",
      "2  2023-08-01     228584.5  94614.25  3646638.0    1715907.5  7.159903e+06   \n",
      "3  2023-09-01     228532.5  96913.50  3880641.0    1623684.0  7.126489e+06   \n",
      "\n",
      "       vivareal           olx  \n",
      "0  6.892801e+06  7.940828e+06  \n",
      "1  6.994696e+06  8.031011e+06  \n",
      "2  7.161266e+06  8.150936e+06  \n",
      "3  7.127475e+06  8.159988e+06  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TOTAL LISTINGS\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "import olx_datalake\n",
    "\n",
    "# Convertendo a data inicial e final para datetime\n",
    "start_date_str = '2023-06-01'\n",
    "start_date = pd.to_datetime(start_date_str)\n",
    "\n",
    "# Converte as datas para objetos datetime\n",
    "start_date = datetime.strptime(start_date_str, '%Y-%m-%d')\n",
    "start_date = start_date.strftime('%Y-%m-%d')\n",
    "#conversoes necessarias:\n",
    "year_str, month_str, day_str = start_date.split('-')\n",
    "\n",
    "# Convert year_str and month_str to integers\n",
    "year = int(year_str)\n",
    "month = int(month_str)\n",
    "\n",
    "#chamada do datalake_olx\n",
    "dl = olx_datalake.DataLake()\n",
    "\n",
    "\n",
    "print(\"Olx_datalake configurado\")\n",
    "\n",
    "#Total listings-olx\n",
    "total_olx = dl.sql(\"\"\"\n",
    "    with \n",
    "\n",
    "cl as (\n",
    "SELECT event_date \n",
    "FROM ods.calendar\n",
    "where cast(array_join(array[year(event_date), month(event_date), day(event_date)], '-') as date) between date('\"\"\"+start_date+\"\"\"') and date('\"\"\"+start_date+\"\"\"')+ interval '4' month\n",
    "\n",
    ")\n",
    "\n",
    ",listings AS \n",
    "(\n",
    "SELECT DISTINCT\n",
    "    CAST(cl.event_date AS DATE) AS data,\n",
    "    a.list_id_nk,\n",
    "    ad.account_id_fk\n",
    "FROM olx_listing.ad_inventory a\n",
    "JOIN  cl ON DATE (a.start_date) <= DATE(cl.event_date) AND coalesce(DATE(a.end_date),current_date) >= DATE(cl.event_date)\n",
    "left join ods.ad ad on a.list_id_nk = ad.list_id_nk\n",
    "LEFT JOIN ods.dm_category ca ON ad.category_id_fk=ca.category_id_pk \n",
    "WHERE category_id_fk in (121, 124, 125, 2, 3, 79, 44, 86, 80, 40)\n",
    ")\n",
    "\n",
    ",daily_ads as (\n",
    "SELECT \n",
    "    data,\n",
    "    COUNT(distinct list_id_nk) AS listings\n",
    "FROM listings\n",
    "GROUP BY 1\n",
    ")\n",
    "\n",
    "select \n",
    "  date_trunc('month', data) as publi_month,\n",
    "  avg(listings) as olx\n",
    "from daily_ads\n",
    "group by 1\n",
    "order by 1\n",
    "\"\"\")\n",
    "\n",
    "#Total listings-Shift\n",
    "total_shift = dl.sql(\"\"\"\n",
    "    with\n",
    "\n",
    "base as (\n",
    "select\n",
    "count(distinct id) as listings,\n",
    "dt as publi_date,\n",
    "date_trunc('month',dt) as publi_month,\n",
    "case when link like '%casamineira.com%' then 'Casa Mineira'\n",
    "     when link like '%loft.com%' then 'Loft'\n",
    "     when link like '%imovelweb.com%' then 'Imovelweb'\n",
    "     when link like '%quintoandar.com%' then 'Quinto Andar' end as player\n",
    "from strategy.shift\n",
    "where dt >= date('\"\"\"+start_date+\"\"\"')\n",
    "group by 2,3,4\n",
    "),\n",
    "\n",
    "mensal as (\n",
    "select\n",
    "publi_month,\n",
    "player,\n",
    "avg(listings) as listings\n",
    "from base\n",
    "group by 1,2\n",
    ")\n",
    "select\n",
    "a.publi_month,\n",
    "a.listings as quintoandar,\n",
    "b.listings as loft,\n",
    "c.listings as imovelweb,\n",
    "d.listings as casamineira\n",
    "from (select * from mensal where player = 'Quinto Andar') as a\n",
    "left join (select * from mensal where player = 'Loft') as b on a.publi_month=b.publi_month\n",
    "left join (select * from mensal where player = 'Imovelweb') as c on a.publi_month=c.publi_month\n",
    "left join (select * from mensal where player = 'Casa Mineira') as d on a.publi_month=d.publi_month\n",
    "order by 1\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "#Total listings-zap/vr\n",
    "total_zap = dl.sql(\"\"\"\n",
    "    with\n",
    "aux as (\n",
    "select dt,\n",
    "       date_trunc('month',dt) as mes,\n",
    "       count(distinct id) as n_listing\n",
    "        from silver_normalized_listings.listings_daily\n",
    "        where True\n",
    "        and dt >=date('\"\"\"+start_date+\"\"\"')\n",
    "        and is_active = true\n",
    "        and is_zap_portal = true\n",
    "        \n",
    "        group by 1,2--,2,3,4,5)\n",
    "        ),\n",
    "   final as (     \n",
    "        select\n",
    "        mes as publi_month,\n",
    "        avg(n_listing) as zap\n",
    "        from aux\n",
    "        group by 1\n",
    "        )\n",
    "select * from final\n",
    "order by publi_month\n",
    "\"\"\")\n",
    "\n",
    "total_vr = dl.sql(\"\"\"\n",
    "    with\n",
    "aux as (\n",
    "select dt,\n",
    "       date_trunc('month',dt) as mes,\n",
    "       count(distinct id) as n_listing\n",
    "        from silver_normalized_listings.listings_daily\n",
    "        where True\n",
    "        and dt >=date('\"\"\"+start_date+\"\"\"')\n",
    "        and is_active = true\n",
    "        and is_vr_portal = true\n",
    "        \n",
    "        group by 1,2--,2,3,4,5)\n",
    "        ),\n",
    "   final as (     \n",
    "        select\n",
    "        mes as publi_month,\n",
    "        avg(n_listing) as vivareal\n",
    "        from aux\n",
    "        group by 1\n",
    "        )\n",
    "select * from final\n",
    "order by publi_month\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "result = total_shift.merge(total_zap, on='publi_month').merge(total_vr, on='publi_month').merge(total_olx, on='publi_month')\n",
    "\n",
    "# Exibindo o resultado\n",
    "print(result_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2f8453b-f697-4e71-8d2d-a396d0156987",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop iter\n",
      "loop iter\n",
      "loop iter\n",
      "loop iter\n",
      "loop iter\n",
      "loop iter\n",
      "loop iter\n",
      "loop iter\n",
      "loop iter\n",
      "Datas atualizadas com sucesso no Google Sheets.\n",
      "Jun/23\n",
      "['casamineira', 'imovelweb', 'loft', 'olx', 'quintoandar', 'vivareal', 'zap']\n",
      "15\n",
      "['casamineira', 'imovelweb', 'loft', 'olx', 'quintoandar', 'vivareal', 'zap']\n",
      "13\n",
      "['casamineira', 'imovelweb', 'loft', 'olx', 'quintoandar', 'vivareal', 'zap']\n",
      "12\n",
      "['casamineira', 'imovelweb', 'loft', 'olx', 'quintoandar', 'vivareal', 'zap']\n",
      "11\n",
      "['casamineira', 'imovelweb', 'loft', 'olx', 'quintoandar', 'vivareal', 'zap']\n",
      "17\n",
      "['casamineira', 'imovelweb', 'loft', 'olx', 'quintoandar', 'vivareal', 'zap']\n",
      "16\n",
      "['casamineira', 'imovelweb', 'loft', 'olx', 'quintoandar', 'vivareal', 'zap']\n",
      "14\n",
      "Jul/23\n",
      "['casamineira', 'imovelweb', 'loft', 'olx', 'quintoandar', 'vivareal', 'zap']\n",
      "15\n",
      "['casamineira', 'imovelweb', 'loft', 'olx', 'quintoandar', 'vivareal', 'zap']\n",
      "13\n",
      "['casamineira', 'imovelweb', 'loft', 'olx', 'quintoandar', 'vivareal', 'zap']\n",
      "12\n",
      "['casamineira', 'imovelweb', 'loft', 'olx', 'quintoandar', 'vivareal', 'zap']\n",
      "11\n",
      "['casamineira', 'imovelweb', 'loft', 'olx', 'quintoandar', 'vivareal', 'zap']\n",
      "17\n",
      "['casamineira', 'imovelweb', 'loft', 'olx', 'quintoandar', 'vivareal', 'zap']\n",
      "16\n",
      "['casamineira', 'imovelweb', 'loft', 'olx', 'quintoandar', 'vivareal', 'zap']\n",
      "14\n",
      "Aug/23\n",
      "['casamineira', 'imovelweb', 'loft', 'olx', 'quintoandar', 'vivareal', 'zap']\n",
      "15\n",
      "['casamineira', 'imovelweb', 'loft', 'olx', 'quintoandar', 'vivareal', 'zap']\n",
      "13\n",
      "['casamineira', 'imovelweb', 'loft', 'olx', 'quintoandar', 'vivareal', 'zap']\n",
      "12\n",
      "['casamineira', 'imovelweb', 'loft', 'olx', 'quintoandar', 'vivareal', 'zap']\n",
      "11\n",
      "['casamineira', 'imovelweb', 'loft', 'olx', 'quintoandar', 'vivareal', 'zap']\n",
      "17\n",
      "['casamineira', 'imovelweb', 'loft', 'olx', 'quintoandar', 'vivareal', 'zap']\n",
      "16\n",
      "['casamineira', 'imovelweb', 'loft', 'olx', 'quintoandar', 'vivareal', 'zap']\n",
      "14\n",
      "Sep/23\n",
      "['casamineira', 'imovelweb', 'loft', 'olx', 'quintoandar', 'vivareal', 'zap']\n",
      "15\n",
      "['casamineira', 'imovelweb', 'loft', 'olx', 'quintoandar', 'vivareal', 'zap']\n",
      "13\n",
      "['casamineira', 'imovelweb', 'loft', 'olx', 'quintoandar', 'vivareal', 'zap']\n",
      "12\n",
      "['casamineira', 'imovelweb', 'loft', 'olx', 'quintoandar', 'vivareal', 'zap']\n",
      "11\n",
      "['casamineira', 'imovelweb', 'loft', 'olx', 'quintoandar', 'vivareal', 'zap']\n",
      "17\n",
      "['casamineira', 'imovelweb', 'loft', 'olx', 'quintoandar', 'vivareal', 'zap']\n",
      "16\n",
      "['casamineira', 'imovelweb', 'loft', 'olx', 'quintoandar', 'vivareal', 'zap']\n",
      "14\n",
      "Dados atualizados com sucesso no Google Sheets.\n"
     ]
    }
   ],
   "source": [
    "#total listings WRITE\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "\n",
    "def encontrar_coluna_por_data(credenciais_json, nome_planilha, nome_aba, data_procurada):\n",
    "\n",
    "    # Abra a planilha e a aba\n",
    "    planilha = client.open(nome_planilha)\n",
    "    aba = planilha.worksheet(nome_aba)\n",
    "\n",
    "    # Obtenha os valores da linha 10 (assumindo que as datas estão na linha 10)\n",
    "    valores_linha_10 = aba.row_values(10)\n",
    "\n",
    "    # Itere pelos valores para encontrar a coluna com a data procurada\n",
    "    for coluna, data in enumerate(valores_linha_10, start=1):\n",
    "        if data == data_procurada:\n",
    "            return coluna\n",
    "\n",
    "    return None  # Retorna None se a data não for encontrada\n",
    "\n",
    "def converter_data(mon_yy):\n",
    "    # Converte a data no formato \"Mon/YY\" para \"01/MM/YY\"\n",
    "    mon_yy = \"01/\" + mon_yy\n",
    "    # Converte a data para o formato \"YYYY-MM-01 00:00:00\"\n",
    "    data_formatada = pd.to_datetime(mon_yy, format=\"%d/%b/%y\")\n",
    "    return data_formatada\n",
    "\n",
    "def dataf_max_date(df):\n",
    "    return df['publi_month'].max()\n",
    "\n",
    "def column_number(col_str):\n",
    "    # Converte uma string de coluna em seu número inteiro correspondente (A=1, B=2, ..., Z=26, AA=27, AB=28, ...)\n",
    "    num = 0\n",
    "    for c in col_str:\n",
    "        num = num * 26 + ord(c) - ord('A') + 1\n",
    "    return num\n",
    "\n",
    "def column_string(column_num):\n",
    "    # Converte um número de coluna em sua representação de string correspondente (1=A, 2=B, ..., 26=Z, 27=AA, 28=AB, ...)\n",
    "    result = \"\"\n",
    "    while column_num > 0:\n",
    "        column_num, remainder = divmod(column_num - 1, 26)\n",
    "        result = chr(ord('A') + remainder) + result\n",
    "    return result\n",
    "\n",
    "\n",
    "def preencher_datas_na_planilha(credenciais_json, nome_planilha, nome_aba, df):\n",
    "    # Carregue as credenciais do Google Sheets\n",
    "    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\n",
    "    creds = ServiceAccountCredentials.from_json_keyfile_name(credenciais_json, scope)\n",
    "    client = gspread.authorize(creds)\n",
    "\n",
    "    # Abra a planilha e a aba\n",
    "    planilha = client.open(nome_planilha)\n",
    "    aba = planilha.worksheet(nome_aba)\n",
    "\n",
    "    # Encontre a maior data no dataframe\n",
    "    data_maxima_dataframe = dataf_max_date(df)\n",
    "    # Comece da primeira célula na linha 10\n",
    "    coluna_atual = 'AM'\n",
    "    celula_atual = aba.acell(f'{coluna_atual}10').value\n",
    "    celula_atual=converter_data(celula_atual)\n",
    "    while celula_atual<data_maxima_dataframe:\n",
    "        # Obtenha o valor da célula atual e da próxima célula\n",
    "        print('loop iter')\n",
    "        celula_atual = aba.acell(f'{coluna_atual}10').value\n",
    "        celula_atual=converter_data(celula_atual)\n",
    "        coluna_proxima_numero = column_number(coluna_atual) + 1\n",
    "        coluna_proxima = column_string(coluna_proxima_numero)\n",
    "        celula_proxima = aba.acell(f'{coluna_proxima}10').value\n",
    "\n",
    "        # Verifique se a próxima célula está preenchida\n",
    "        if not celula_proxima:\n",
    "            # Se a célula atual estiver vazia, preencha com a data um mês à frente\n",
    "            nova_data =celula_atual+ timedelta(days=31)\n",
    "            nova_data = nova_data.replace(day=1)  # Define o dia para 1 para garantir que seja o primeiro dia do mês\n",
    "            data_atual_str = nova_data.strftime('%b/%y')\n",
    "            aba.update_acell(f'{coluna_proxima}10', data_atual_str)\n",
    "            # Avance para a próxima coluna\n",
    "        coluna_atual = coluna_proxima\n",
    "            \n",
    "\n",
    "    print('Datas atualizadas com sucesso no Google Sheets.')\n",
    "\n",
    "# Defina o nome do seu arquivo JSON de credenciais do Google\n",
    "credenciais_json = 'project-bht-e1805246c668.json'\n",
    "\n",
    "# Defina o nome do arquivo do Google Sheets e a aba\n",
    "nome_planilha = 'Q2-23 Competition KPI collection file - Brasil'\n",
    "nome_aba = '(datalake) Listings RE'\n",
    "\n",
    "# Carregue as credenciais do Google Sheets\n",
    "scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name(credenciais_json, scope)\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "# Abra a planilha e a aba\n",
    "planilha = client.open(nome_planilha)\n",
    "aba = planilha.worksheet(nome_aba)\n",
    "\n",
    "# Carregue o dataframe\n",
    "df = result_total  \n",
    "preencher_datas_na_planilha(credenciais_json, nome_planilha, nome_aba, df)\n",
    "\n",
    "# Preencha as células com os dados do dataframe\n",
    "colunas_players = df.columns[df.columns != 'publi_month']  # Obtém as colunas dos players\n",
    "for index, row in df.iterrows():\n",
    "    data = row['publi_month'].strftime('%b/%y')\n",
    "    print(data)\n",
    "\n",
    "    # Encontre a coluna correspondente à data\n",
    "    coluna_data =encontrar_coluna_por_data(credenciais_json, nome_planilha, nome_aba, data)\n",
    "\n",
    "    # Atualize as células com os valores dos players\n",
    "    for player in colunas_players:\n",
    "        valor = row[player]\n",
    "        coluna_a = aba.col_values(1)\n",
    "        coluna_a=coluna_a[10:17]\n",
    "        print(coluna_a)\n",
    "        for linha, site in enumerate(coluna_a, start=11):\n",
    "            if site.lower() == player.lower():\n",
    "                linha_player=linha\n",
    "                print(linha_player)\n",
    "        aba.update_acell(f'{column_string(coluna_data)}{linha_player}', valor)\n",
    "\n",
    "print('Dados atualizados com sucesso no Google Sheets.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6974484-a761-4708-87fc-b759405db333",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olx_datalake configurado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FINISHED: 100%|██████████| 8218/8218 [01:55<00:00, 71.31 splits/s] \n",
      "FINISHED: 100%|██████████| 6487/6487 [00:38<00:00, 169.12 splits/s]\n",
      "FINISHED: 100%|██████████| 2829/2829 [00:38<00:00, 72.58 splits/s]\n",
      "FINISHED: 100%|██████████| 2690/2690 [00:33<00:00, 81.47 splits/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  publi_month  quintoandar      loft   imovelweb  casamineira           zap  \\\n",
      "0  2023-06-01    190023.60  91472.40  3379890.60   1776472.40  6.071932e+06   \n",
      "1  2023-07-01    195828.25  93198.25  3064799.00   1651812.75  6.156234e+06   \n",
      "2  2023-08-01    200741.75  94614.25  3379743.25   1547933.50  6.297289e+06   \n",
      "3  2023-09-01    200034.00  96913.50  3604521.50   1468791.50  6.256694e+06   \n",
      "\n",
      "       vivareal           olx  \n",
      "0  6.071003e+06  6.795308e+06  \n",
      "1  6.155364e+06  6.864544e+06  \n",
      "2  6.297417e+06  6.961385e+06  \n",
      "3  6.257130e+06  6.959081e+06  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# SALE LISTINGS\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "import olx_datalake\n",
    "\n",
    "# Convertendo a data inicial e final para datetime\n",
    "start_date_str = '2023-06-01'\n",
    "start_date = pd.to_datetime(start_date_str)\n",
    "\n",
    "# Converte as datas para objetos datetime\n",
    "start_date = datetime.strptime(start_date_str, '%Y-%m-%d')\n",
    "start_date = start_date.strftime('%Y-%m-%d')\n",
    "#conversoes necessarias:\n",
    "year_str, month_str, day_str = start_date.split('-')\n",
    "\n",
    "# Convert year_str and month_str to integers\n",
    "year = int(year_str)\n",
    "month = int(month_str)\n",
    "\n",
    "#chamada do datalake_olx\n",
    "dl = olx_datalake.DataLake()\n",
    "\n",
    "\n",
    "print(\"Olx_datalake configurado\")\n",
    "\n",
    "#Sale listings-olx\n",
    "sale_olx = dl.sql(\"\"\"\n",
    "    with \n",
    "\n",
    "cl as (\n",
    "SELECT event_date \n",
    "FROM ods.calendar\n",
    "where cast(array_join(array[year(event_date), month(event_date), day(event_date)], '-') as date) between date('\"\"\"+start_date+\"\"\"') and date('\"\"\"+start_date+\"\"\"')+ interval '4' month\n",
    "\n",
    ")\n",
    "\n",
    ",listings AS \n",
    "(\n",
    "SELECT DISTINCT\n",
    "    CAST(cl.event_date AS DATE) AS data,\n",
    "    a.list_id_nk,\n",
    "    ad.account_id_fk,\n",
    "    case when ad_type_id_fk=1 then 'venda'\n",
    "    when ad_type_id_fk=3 then 'aluguel' end as negocio\n",
    "FROM olx_listing.ad_inventory a\n",
    "JOIN  cl \n",
    "    ON DATE (a.start_date) <= DATE(cl.event_date) AND coalesce(DATE(a.end_date),current_date) >= DATE(cl.event_date)\n",
    "left join ods.ad ad on a.list_id_nk = ad.list_id_nk\n",
    "LEFT JOIN ods.dm_category ca ON ad.category_id_fk=ca.category_id_pk \n",
    "left join ods.dm_ad_type as neg on neg.ad_type_id_pk = ad.ad_type_id_fk\n",
    "WHERE category_id_fk in (121, 124, 125, 2, 3, 79, 44, 86, 80, 40)\n",
    ")\n",
    "\n",
    ",daily_ads as (\n",
    "SELECT \n",
    "    data,\n",
    "    COUNT(distinct list_id_nk) AS listings\n",
    "FROM listings\n",
    "where negocio='venda'\n",
    "GROUP BY 1\n",
    ")\n",
    "\n",
    "select \n",
    "  date_trunc('month', data) as publi_month,\n",
    "  avg(listings) as olx\n",
    "from daily_ads\n",
    "group by 1\n",
    "order by 1\n",
    "\"\"\")\n",
    "\n",
    "#Sale listings-Shift\n",
    "sale_shift = dl.sql(\"\"\"\n",
    "    with\n",
    "\n",
    "base as (\n",
    "select\n",
    "count(distinct id) as listings,\n",
    "dt as publi_date,\n",
    "date_trunc('month',dt) as publi_month,\n",
    "case when link like '%casamineira.com%' then 'Casa Mineira'\n",
    "     when link like '%loft.com%' then 'Loft'\n",
    "     when link like '%imovelweb.com%' then 'Imovelweb'\n",
    "     when link like '%quintoandar.com%' then 'Quinto Andar' end as player\n",
    "from strategy.shift\n",
    "where dt >= date('\"\"\"+start_date+\"\"\"')\n",
    "and tipo in (1,2) -- venda\n",
    "group by 2,3,4\n",
    "),\n",
    "\n",
    "mensal as (\n",
    "select\n",
    "publi_month,\n",
    "player,\n",
    "avg(listings) as listings\n",
    "from base\n",
    "group by 1,2\n",
    ")\n",
    "select\n",
    "a.publi_month,\n",
    "a.listings as quintoandar,\n",
    "b.listings as loft,\n",
    "c.listings as imovelweb,\n",
    "d.listings as casamineira\n",
    "from (select * from mensal where player = 'Quinto Andar') as a\n",
    "left join (select * from mensal where player = 'Loft') as b on a.publi_month=b.publi_month\n",
    "left join (select * from mensal where player = 'Imovelweb') as c on a.publi_month=c.publi_month\n",
    "left join (select * from mensal where player = 'Casa Mineira') as d on a.publi_month=d.publi_month\n",
    "order by 1\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "#sale listings-zap/vr\n",
    "sale_zap = dl.sql(\"\"\"\n",
    "    with\n",
    "aux as (\n",
    "select dt,\n",
    "       date_trunc('month',dt) as mes,\n",
    "       count(distinct id) as n_listing\n",
    "        from silver_normalized_listings.listings_daily\n",
    "        where True\n",
    "        and dt >=date('\"\"\"+start_date+\"\"\"')\n",
    "        and is_active = true\n",
    "        and is_zap_portal = true\n",
    "        and is_sale = true\n",
    "        \n",
    "        group by 1,2--,2,3,4,5)\n",
    "        ),\n",
    "   final as (     \n",
    "        select\n",
    "        mes as publi_month,\n",
    "        avg(n_listing) as zap\n",
    "        from aux\n",
    "        group by 1\n",
    "        )\n",
    "select * from final\n",
    "order by publi_month\n",
    "\"\"\")\n",
    "\n",
    "sale_vr = dl.sql(\"\"\"\n",
    "    with\n",
    "aux as (\n",
    "select dt,\n",
    "       date_trunc('month',dt) as mes,\n",
    "       count(distinct id) as n_listing\n",
    "        from silver_normalized_listings.listings_daily\n",
    "        where True\n",
    "        and dt >=date('\"\"\"+start_date+\"\"\"')\n",
    "        and is_active = true\n",
    "        and is_vr_portal = true\n",
    "        and is_sale = true\n",
    "        \n",
    "        group by 1,2--,2,3,4,5)\n",
    "        ),\n",
    "   final as (     \n",
    "        select\n",
    "        mes as publi_month,\n",
    "        avg(n_listing) as vivareal\n",
    "        from aux\n",
    "        group by 1\n",
    "        )\n",
    "select * from final\n",
    "order by publi_month\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "result_sale = sale_shift.merge(sale_zap, on='publi_month').merge(sale_vr, on='publi_month').merge(sale_olx, on='publi_month')\n",
    "\n",
    "# Exibindo o resultado\n",
    "print(result_sale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8122d6c1-faaa-4740-af72-cb2a1e13d90b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop iter\n",
      "loop iter\n",
      "loop iter\n",
      "loop iter\n",
      "loop iter\n",
      "loop iter\n",
      "loop iter\n",
      "loop iter\n",
      "loop iter\n",
      "Datas atualizadas com sucesso no Google Sheets.\n",
      "Jun/23\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "23\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "21\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "20\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "19\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "25\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "24\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "22\n",
      "Jul/23\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "23\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "21\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "20\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "19\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "25\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "24\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "22\n",
      "Aug/23\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "23\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "21\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "20\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "19\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "25\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "24\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "22\n",
      "Sep/23\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "23\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "21\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "20\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "19\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "25\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "24\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "22\n",
      "Dados atualizados com sucesso no Google Sheets.\n"
     ]
    }
   ],
   "source": [
    "#sale listings WRITE\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "\n",
    "def encontrar_coluna_por_data(credenciais_json, nome_planilha, nome_aba, data_procurada):\n",
    "\n",
    "    # Abra a planilha e a aba\n",
    "    planilha = client.open(nome_planilha)\n",
    "    aba = planilha.worksheet(nome_aba)\n",
    "\n",
    "    # Obtenha os valores da linha 10 (assumindo que as datas estão na linha 10)\n",
    "    valores_linha_10 = aba.row_values(10)\n",
    "\n",
    "    # Itere pelos valores para encontrar a coluna com a data procurada\n",
    "    for coluna, data in enumerate(valores_linha_10, start=1):\n",
    "        if data == data_procurada:\n",
    "            return coluna\n",
    "\n",
    "    return None  # Retorna None se a data não for encontrada\n",
    "\n",
    "def converter_data(mon_yy):\n",
    "    # Converte a data no formato \"Mon/YY\" para \"01/MM/YY\"\n",
    "    mon_yy = \"01/\" + mon_yy\n",
    "    # Converte a data para o formato \"YYYY-MM-01 00:00:00\"\n",
    "    data_formatada = pd.to_datetime(mon_yy, format=\"%d/%b/%y\")\n",
    "    return data_formatada\n",
    "\n",
    "def dataf_max_date(df):\n",
    "    return df['publi_month'].max()\n",
    "\n",
    "def column_number(col_str):\n",
    "    # Converte uma string de coluna em seu número inteiro correspondente (A=1, B=2, ..., Z=26, AA=27, AB=28, ...)\n",
    "    num = 0\n",
    "    for c in col_str:\n",
    "        num = num * 26 + ord(c) - ord('A') + 1\n",
    "    return num\n",
    "\n",
    "def column_string(column_num):\n",
    "    # Converte um número de coluna em sua representação de string correspondente (1=A, 2=B, ..., 26=Z, 27=AA, 28=AB, ...)\n",
    "    result = \"\"\n",
    "    while column_num > 0:\n",
    "        column_num, remainder = divmod(column_num - 1, 26)\n",
    "        result = chr(ord('A') + remainder) + result\n",
    "    return result\n",
    "\n",
    "\n",
    "def preencher_datas_na_planilha(credenciais_json, nome_planilha, nome_aba, df):\n",
    "    # Carregue as credenciais do Google Sheets\n",
    "    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\n",
    "    creds = ServiceAccountCredentials.from_json_keyfile_name(credenciais_json, scope)\n",
    "    client = gspread.authorize(creds)\n",
    "\n",
    "    # Abra a planilha e a aba\n",
    "    planilha = client.open(nome_planilha)\n",
    "    aba = planilha.worksheet(nome_aba)\n",
    "\n",
    "    # Encontre a maior data no dataframe\n",
    "    data_maxima_dataframe = dataf_max_date(df)\n",
    "    # Comece da primeira célula na linha 10\n",
    "    coluna_atual = 'AM'\n",
    "    celula_atual = aba.acell(f'{coluna_atual}10').value\n",
    "    celula_atual=converter_data(celula_atual)\n",
    "    while celula_atual<data_maxima_dataframe:\n",
    "        # Obtenha o valor da célula atual e da próxima célula\n",
    "        print('loop iter')\n",
    "        celula_atual = aba.acell(f'{coluna_atual}10').value\n",
    "        celula_atual=converter_data(celula_atual)\n",
    "        coluna_proxima_numero = column_number(coluna_atual) + 1\n",
    "        coluna_proxima = column_string(coluna_proxima_numero)\n",
    "        celula_proxima = aba.acell(f'{coluna_proxima}10').value\n",
    "\n",
    "        # Verifique se a próxima célula está preenchida\n",
    "        if not celula_proxima:\n",
    "            # Se a célula atual estiver vazia, preencha com a data um mês à frente\n",
    "            nova_data =celula_atual+ timedelta(days=31)\n",
    "            nova_data = nova_data.replace(day=1)  # Define o dia para 1 para garantir que seja o primeiro dia do mês\n",
    "            data_atual_str = nova_data.strftime('%b/%y')\n",
    "            aba.update_acell(f'{coluna_proxima}10', data_atual_str)\n",
    "            # Avance para a próxima coluna\n",
    "        coluna_atual = coluna_proxima\n",
    "            \n",
    "\n",
    "    print('Datas atualizadas com sucesso no Google Sheets.')\n",
    "\n",
    "# Defina o nome do seu arquivo JSON de credenciais do Google\n",
    "credenciais_json = 'project-bht-e1805246c668.json'\n",
    "\n",
    "# Defina o nome do arquivo do Google Sheets e a aba\n",
    "nome_planilha = 'Q2-23 Competition KPI collection file - Brasil'\n",
    "nome_aba = '(datalake) Listings RE'\n",
    "\n",
    "# Carregue as credenciais do Google Sheets\n",
    "scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name(credenciais_json, scope)\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "# Abra a planilha e a aba\n",
    "planilha = client.open(nome_planilha)\n",
    "aba = planilha.worksheet(nome_aba)\n",
    "\n",
    "# Carregue o dataframe\n",
    "df = result_sale  \n",
    "preencher_datas_na_planilha(credenciais_json, nome_planilha, nome_aba, df)\n",
    "\n",
    "# Preencha as células com os dados do dataframe\n",
    "colunas_players = df.columns[df.columns != 'publi_month']  # Obtém as colunas dos players\n",
    "for index, row in df.iterrows():\n",
    "    data = row['publi_month'].strftime('%b/%y')\n",
    "    print(data)\n",
    "\n",
    "    # Encontre a coluna correspondente à data\n",
    "    coluna_data =encontrar_coluna_por_data(credenciais_json, nome_planilha, nome_aba, data)\n",
    "\n",
    "    # Atualize as células com os valores dos players\n",
    "    for player in colunas_players:\n",
    "        valor = row[player]\n",
    "        coluna_a = aba.col_values(1)\n",
    "        coluna_a=coluna_a[18:25]\n",
    "        print(coluna_a)\n",
    "        for linha, site in enumerate(coluna_a, start=19):\n",
    "            if site.lower() == player.lower():\n",
    "                linha_player=linha\n",
    "                print(linha_player)\n",
    "        aba.update_acell(f'{column_string(coluna_data)}{linha_player}', valor)\n",
    "\n",
    "print('Dados atualizados com sucesso no Google Sheets.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3068ccb6-7777-404a-a9df-2538565ee5c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olx_datalake configurado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FINISHED: 100%|██████████| 7868/7868 [02:20<00:00, 55.88 splits/s]\n",
      "FINISHED: 100%|██████████| 6229/6229 [00:14<00:00, 441.45 splits/s]\n",
      "FINISHED: 100%|██████████| 2277/2277 [00:44<00:00, 51.47 splits/s]\n",
      "FINISHED: 100%|██████████| 2802/2802 [00:32<00:00, 86.80 splits/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  publi_month  quintoandar  loft  imovelweb  casamineira           zap  \\\n",
      "0  2023-06-01    107365.60   NaN   430427.8    189228.20  9.852658e+05   \n",
      "1  2023-07-01    110412.75   NaN   464267.0    182145.75  1.008030e+06   \n",
      "2  2023-08-01    112375.75   NaN   359731.5    167974.00  1.038758e+06   \n",
      "3  2023-09-01    114703.00   NaN   377866.5    154892.50  1.045300e+06   \n",
      "\n",
      "       vivareal           olx  \n",
      "0  9.871059e+05  1.145520e+06  \n",
      "1  1.009830e+06  1.166467e+06  \n",
      "2  1.039999e+06  1.189551e+06  \n",
      "3  1.045857e+06  1.200908e+06  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# RENTAL LISTINGS\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "import olx_datalake\n",
    "\n",
    "# Convertendo a data inicial e final para datetime\n",
    "start_date_str = '2023-06-01'\n",
    "start_date = pd.to_datetime(start_date_str)\n",
    "\n",
    "# Converte as datas para objetos datetime\n",
    "start_date = datetime.strptime(start_date_str, '%Y-%m-%d')\n",
    "start_date = start_date.strftime('%Y-%m-%d')\n",
    "#conversoes necessarias:\n",
    "year_str, month_str, day_str = start_date.split('-')\n",
    "\n",
    "# Convert year_str and month_str to integers\n",
    "year = int(year_str)\n",
    "month = int(month_str)\n",
    "\n",
    "#chamada do datalake_olx\n",
    "dl = olx_datalake.DataLake()\n",
    "\n",
    "\n",
    "print(\"Olx_datalake configurado\")\n",
    "\n",
    "#Rental listings-olx\n",
    "rental_olx = dl.sql(\"\"\"\n",
    "    with \n",
    "\n",
    "cl as (\n",
    "SELECT event_date \n",
    "FROM ods.calendar\n",
    "where cast(array_join(array[year(event_date), month(event_date), day(event_date)], '-') as date) between date('\"\"\"+start_date+\"\"\"') and date('\"\"\"+start_date+\"\"\"')+ interval '4' month\n",
    "\n",
    ")\n",
    "\n",
    ",listings AS \n",
    "(\n",
    "SELECT DISTINCT\n",
    "    CAST(cl.event_date AS DATE) AS data,\n",
    "    a.list_id_nk,\n",
    "    ad.account_id_fk,\n",
    "    case when ad_type_id_fk=1 then 'venda'\n",
    "    when ad_type_id_fk=3 then 'aluguel' end as negocio\n",
    "FROM olx_listing.ad_inventory a\n",
    "JOIN  cl \n",
    "    ON DATE (a.start_date) <= DATE(cl.event_date) AND coalesce(DATE(a.end_date),current_date) >= DATE(cl.event_date)\n",
    "left join ods.ad ad on a.list_id_nk = ad.list_id_nk\n",
    "LEFT JOIN ods.dm_category ca ON ad.category_id_fk=ca.category_id_pk \n",
    "left join ods.dm_ad_type as neg on neg.ad_type_id_pk = ad.ad_type_id_fk\n",
    "WHERE category_id_fk in (121, 124, 125, 2, 3, 79, 44, 86, 80, 40)\n",
    ")\n",
    "\n",
    ",daily_ads as (\n",
    "SELECT \n",
    "    data,\n",
    "    COUNT(distinct list_id_nk) AS listings\n",
    "FROM listings\n",
    "where negocio='aluguel'\n",
    "GROUP BY 1\n",
    ")\n",
    "\n",
    "select \n",
    "  date_trunc('month', data) as publi_month,\n",
    "  avg(listings) as olx\n",
    "from daily_ads\n",
    "group by 1\n",
    "order by 1\n",
    "\"\"\")\n",
    "\n",
    "#Rental listings-Shift\n",
    "rental_shift = dl.sql(\"\"\"\n",
    "    with\n",
    "\n",
    "base as (\n",
    "select\n",
    "count(distinct id) as listings,\n",
    "dt as publi_date,\n",
    "date_trunc('month',dt) as publi_month,\n",
    "case when link like '%casamineira.com%' then 'Casa Mineira'\n",
    "     when link like '%loft.com%' then 'Loft'\n",
    "     when link like '%imovelweb.com%' then 'Imovelweb'\n",
    "     when link like '%quintoandar.com%' then 'Quinto Andar' end as player\n",
    "from strategy.shift\n",
    "where dt >= date('\"\"\"+start_date+\"\"\"')\n",
    "and tipo in (0,2) -- aluguel\n",
    "group by 2,3,4\n",
    "),\n",
    "\n",
    "mensal as (\n",
    "select\n",
    "publi_month,\n",
    "player,\n",
    "avg(listings) as listings\n",
    "from base\n",
    "group by 1,2\n",
    ")\n",
    "select\n",
    "a.publi_month,\n",
    "a.listings as quintoandar,\n",
    "b.listings as loft,\n",
    "c.listings as imovelweb,\n",
    "d.listings as casamineira\n",
    "from (select * from mensal where player = 'Quinto Andar') as a\n",
    "left join (select * from mensal where player = 'Loft') as b on a.publi_month=b.publi_month\n",
    "left join (select * from mensal where player = 'Imovelweb') as c on a.publi_month=c.publi_month\n",
    "left join (select * from mensal where player = 'Casa Mineira') as d on a.publi_month=d.publi_month\n",
    "order by 1\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "#Rental listings-zap/vr\n",
    "rental_zap = dl.sql(\"\"\"\n",
    "    with\n",
    "aux as (\n",
    "select dt,\n",
    "       date_trunc('month',dt) as mes,\n",
    "       count(distinct id) as n_listing\n",
    "        from silver_normalized_listings.listings_daily\n",
    "        where True\n",
    "        and dt >=date('\"\"\"+start_date+\"\"\"')\n",
    "        and is_active = true\n",
    "        and is_zap_portal = true\n",
    "         and is_rental = true\n",
    "        \n",
    "        group by 1,2--,2,3,4,5)\n",
    "        ),\n",
    "   final as (     \n",
    "        select\n",
    "        mes as publi_month,\n",
    "        avg(n_listing) as zap\n",
    "        from aux\n",
    "        group by 1\n",
    "        )\n",
    "select * from final\n",
    "order by publi_month\n",
    "\"\"\")\n",
    "\n",
    "rental_vr = dl.sql(\"\"\"\n",
    "    with\n",
    "aux as (\n",
    "select dt,\n",
    "       date_trunc('month',dt) as mes,\n",
    "       count(distinct id) as n_listing\n",
    "        from silver_normalized_listings.listings_daily\n",
    "        where True\n",
    "        and dt >=date('\"\"\"+start_date+\"\"\"')\n",
    "        and is_active = true\n",
    "        and is_vr_portal = true\n",
    "         and is_rental = true\n",
    "        \n",
    "        group by 1,2--,2,3,4,5)\n",
    "        ),\n",
    "   final as (     \n",
    "        select\n",
    "        mes as publi_month,\n",
    "        avg(n_listing) as vivareal\n",
    "        from aux\n",
    "        group by 1\n",
    "        )\n",
    "select * from final\n",
    "order by publi_month\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "result_rental = rental_shift.merge(rental_zap, on='publi_month').merge(rental_vr, on='publi_month').merge(rental_olx, on='publi_month')\n",
    "\n",
    "# Exibindo o resultado\n",
    "print(result_rental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4ce904b-2b79-4a1e-af91-c9bcfd917bf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop iter\n",
      "loop iter\n",
      "loop iter\n",
      "loop iter\n",
      "loop iter\n",
      "loop iter\n",
      "loop iter\n",
      "loop iter\n",
      "loop iter\n",
      "Datas atualizadas com sucesso no Google Sheets.\n",
      "Jun/23\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "31\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "29\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "28\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "27\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "33\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "32\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "30\n",
      "Jul/23\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "31\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "29\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "28\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "27\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "33\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "32\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "30\n",
      "Aug/23\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "31\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "29\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "28\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "27\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "33\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "32\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "30\n",
      "Sep/23\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "31\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "29\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "28\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "27\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "33\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "32\n",
      "['CasaMineira', 'ImovelWeb', 'Loft', 'OLX', 'QuintoAndar', 'VivaReal', 'ZAP']\n",
      "30\n",
      "Dados atualizados com sucesso no Google Sheets.\n"
     ]
    }
   ],
   "source": [
    "#Rental listings WRITE\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "\n",
    "def encontrar_coluna_por_data(credenciais_json, nome_planilha, nome_aba, data_procurada):\n",
    "\n",
    "    # Abra a planilha e a aba\n",
    "    planilha = client.open(nome_planilha)\n",
    "    aba = planilha.worksheet(nome_aba)\n",
    "\n",
    "    # Obtenha os valores da linha 10 (assumindo que as datas estão na linha 10)\n",
    "    valores_linha_10 = aba.row_values(10)\n",
    "\n",
    "    # Itere pelos valores para encontrar a coluna com a data procurada\n",
    "    for coluna, data in enumerate(valores_linha_10, start=1):\n",
    "        if data == data_procurada:\n",
    "            return coluna\n",
    "\n",
    "    return None  # Retorna None se a data não for encontrada\n",
    "\n",
    "def converter_data(mon_yy):\n",
    "    # Converte a data no formato \"Mon/YY\" para \"01/MM/YY\"\n",
    "    mon_yy = \"01/\" + mon_yy\n",
    "    # Converte a data para o formato \"YYYY-MM-01 00:00:00\"\n",
    "    data_formatada = pd.to_datetime(mon_yy, format=\"%d/%b/%y\")\n",
    "    return data_formatada\n",
    "\n",
    "def dataf_max_date(df):\n",
    "    return df['publi_month'].max()\n",
    "\n",
    "def column_number(col_str):\n",
    "    # Converte uma string de coluna em seu número inteiro correspondente (A=1, B=2, ..., Z=26, AA=27, AB=28, ...)\n",
    "    num = 0\n",
    "    for c in col_str:\n",
    "        num = num * 26 + ord(c) - ord('A') + 1\n",
    "    return num\n",
    "\n",
    "def column_string(column_num):\n",
    "    # Converte um número de coluna em sua representação de string correspondente (1=A, 2=B, ..., 26=Z, 27=AA, 28=AB, ...)\n",
    "    result = \"\"\n",
    "    while column_num > 0:\n",
    "        column_num, remainder = divmod(column_num - 1, 26)\n",
    "        result = chr(ord('A') + remainder) + result\n",
    "    return result\n",
    "\n",
    "def substituir_nan_por_zero(df):\n",
    "    # Substitui todos os valores NaN por zero no DataFrame\n",
    "    df_sem_nan = df.fillna(0)\n",
    "    return df_sem_nan\n",
    "\n",
    "def preencher_datas_na_planilha(credenciais_json, nome_planilha, nome_aba, df):\n",
    "    # Carregue as credenciais do Google Sheets\n",
    "    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\n",
    "    creds = ServiceAccountCredentials.from_json_keyfile_name(credenciais_json, scope)\n",
    "    client = gspread.authorize(creds)\n",
    "\n",
    "    # Abra a planilha e a aba\n",
    "    planilha = client.open(nome_planilha)\n",
    "    aba = planilha.worksheet(nome_aba)\n",
    "\n",
    "    # Encontre a maior data no dataframe\n",
    "    data_maxima_dataframe = dataf_max_date(df)\n",
    "    # Comece da primeira célula na linha 10\n",
    "    coluna_atual = 'AM'\n",
    "    celula_atual = aba.acell(f'{coluna_atual}10').value\n",
    "    celula_atual=converter_data(celula_atual)\n",
    "    while celula_atual<data_maxima_dataframe:\n",
    "        # Obtenha o valor da célula atual e da próxima célula\n",
    "        print('loop iter')\n",
    "        celula_atual = aba.acell(f'{coluna_atual}10').value\n",
    "        celula_atual=converter_data(celula_atual)\n",
    "        coluna_proxima_numero = column_number(coluna_atual) + 1\n",
    "        coluna_proxima = column_string(coluna_proxima_numero)\n",
    "        celula_proxima = aba.acell(f'{coluna_proxima}10').value\n",
    "\n",
    "        # Verifique se a próxima célula está preenchida\n",
    "        if not celula_proxima:\n",
    "            # Se a célula atual estiver vazia, preencha com a data um mês à frente\n",
    "            nova_data =celula_atual+ timedelta(days=31)\n",
    "            nova_data = nova_data.replace(day=1)  # Define o dia para 1 para garantir que seja o primeiro dia do mês\n",
    "            data_atual_str = nova_data.strftime('%b/%y')\n",
    "            aba.update_acell(f'{coluna_proxima}10', data_atual_str)\n",
    "            # Avance para a próxima coluna\n",
    "        coluna_atual = coluna_proxima\n",
    "            \n",
    "\n",
    "    print('Datas atualizadas com sucesso no Google Sheets.')\n",
    "\n",
    "# Defina o nome do seu arquivo JSON de credenciais do Google\n",
    "credenciais_json = 'project-bht-e1805246c668.json'\n",
    "\n",
    "# Defina o nome do arquivo do Google Sheets e a aba\n",
    "nome_planilha = 'Q2-23 Competition KPI collection file - Brasil'\n",
    "nome_aba = '(datalake) Listings RE'\n",
    "\n",
    "# Carregue as credenciais do Google Sheets\n",
    "scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name(credenciais_json, scope)\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "# Abra a planilha e a aba\n",
    "planilha = client.open(nome_planilha)\n",
    "aba = planilha.worksheet(nome_aba)\n",
    "\n",
    "# Carregue o dataframe\n",
    "df = substituir_nan_por_zero(result_rental)  \n",
    "preencher_datas_na_planilha(credenciais_json, nome_planilha, nome_aba, df)\n",
    "\n",
    "# Preencha as células com os dados do dataframe\n",
    "colunas_players = df.columns[df.columns != 'publi_month']  # Obtém as colunas dos players\n",
    "for index, row in df.iterrows():\n",
    "    data = row['publi_month'].strftime('%b/%y')\n",
    "    print(data)\n",
    "\n",
    "    # Encontre a coluna correspondente à data\n",
    "    coluna_data =encontrar_coluna_por_data(credenciais_json, nome_planilha, nome_aba, data)\n",
    "\n",
    "    # Atualize as células com os valores dos players\n",
    "    for player in colunas_players:\n",
    "        valor = row[player]\n",
    "        coluna_a = aba.col_values(1)\n",
    "        coluna_a=coluna_a[26:33]\n",
    "        print(coluna_a)\n",
    "        for linha, site in enumerate(coluna_a, start=27):\n",
    "            if site.lower() == player.lower():\n",
    "                linha_player=linha\n",
    "                print(linha_player)\n",
    "        aba.update_acell(f'{column_string(coluna_data)}{linha_player}', valor)\n",
    "\n",
    "print('Dados atualizados com sucesso no Google Sheets.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de909d84-a273-4b82-b738-e43b5696ccd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
